#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹è¯è½¬æ¢æµæ°´çº¿

å®ç°å®Œæ•´çš„å¯¹è¯æ•°æ®å¤„ç†æµç¨‹ï¼š
1. ä½¿ç”¨DialogueLoaderåŠ è½½SGDå¯¹è¯æ•°æ®
2. ä½¿ç”¨PersonalityAdderä¸ºå¯¹è¯æ·»åŠ æ€§æ ¼æ ‡ç­¾
3. å¯¼å‡ºå¤„ç†åçš„æ•°æ®ä¸ºJSONæ ¼å¼

æ”¯æŒå¤šç§æ•°æ®è·å–æ–¹å¼å’Œå¤„ç†é…ç½®ã€‚
"""

import json
import os
import sys
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from MPEAF.dialogue_loader import DialogueLoader
from MPEAF.personality_adder import PersonalityAdder


class TransformationPipeline:
    """
    å¯¹è¯è½¬æ¢æµæ°´çº¿ç±»
    
    è´Ÿè´£åè°ƒæ•´ä¸ªæ•°æ®å¤„ç†æµç¨‹ï¼š
    1. æ•°æ®åŠ è½½
    2. æ€§æ ¼æ ‡ç­¾æ·»åŠ 
    3. æ•°æ®å¯¼å‡º
    """
    
    def __init__(self, 
                 data_dir: str = "datasets/sgd_processed",
                 output_dir: str = "output",
                 random_seed: Optional[int] = None,
                 load_all_data: bool = True):
        """
        åˆå§‹åŒ–è½¬æ¢æµæ°´çº¿
        
        Args:
            data_dir: SGDæ•°æ®ç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            random_seed: éšæœºç§å­ï¼Œç”¨äºç¡®ä¿ç»“æœå¯é‡ç°
            load_all_data: æ˜¯å¦åœ¨åˆå§‹åŒ–æ—¶åŠ è½½æ‰€æœ‰æ•°æ®
        """
        self.data_dir = data_dir
        self.output_dir = output_dir
        self.random_seed = random_seed
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        print("ğŸ—ï¸  åˆå§‹åŒ–è½¬æ¢æµæ°´çº¿")
        print("=" * 60)
        print(f"æ•°æ®ç›®å½•: {data_dir}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"éšæœºç§å­: {random_seed if random_seed is not None else 'æœªè®¾ç½®'}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        try:
            print("\nğŸ“š åˆå§‹åŒ–å¯¹è¯åŠ è½½å™¨...")
            self.dialogue_loader = DialogueLoader(
                data_dir=data_dir, 
                load_all=load_all_data
            )
            
            print("\nğŸ¯ åˆå§‹åŒ–æ€§æ ¼æ·»åŠ å™¨...")
            self.personality_adder = PersonalityAdder(random_seed=random_seed)
            
            print("\nâœ… æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def load_dialogues_by_id(self, dialogue_ids: List[str]) -> List[Dict[str, Any]]:
        """
        æ ¹æ®å¯¹è¯IDåˆ—è¡¨åŠ è½½å¯¹è¯æ•°æ®
        
        Args:
            dialogue_ids: å¯¹è¯IDåˆ—è¡¨
            
        Returns:
            å¯¹è¯æ•°æ®åˆ—è¡¨
        """
        print(f"\nğŸ“‹ æ ¹æ®IDåŠ è½½å¯¹è¯æ•°æ® (å…±{len(dialogue_ids)}ä¸ª)")
        
        dialogues = []
        for dialogue_id in dialogue_ids:
            dialogue = self.dialogue_loader.get_dialogue_by_id(dialogue_id)
            if dialogue:
                dialogues.append(dialogue)
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°å¯¹è¯ID: {dialogue_id}")
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dialogues)}/{len(dialogue_ids)} ä¸ªå¯¹è¯")
        return dialogues
    
    def load_dialogues_by_service(self, 
                                 service: str, 
                                 count: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        æ ¹æ®æœåŠ¡ç±»å‹åŠ è½½å¯¹è¯æ•°æ®
        
        Args:
            service: æœåŠ¡ç±»å‹
            count: åŠ è½½æ•°é‡é™åˆ¶
            
        Returns:
            å¯¹è¯æ•°æ®åˆ—è¡¨
        """
        print(f"\nğŸ“‹ æ ¹æ®æœåŠ¡ç±»å‹åŠ è½½å¯¹è¯æ•°æ®")
        print(f"æœåŠ¡ç±»å‹: {service}")
        print(f"æ•°é‡é™åˆ¶: {count if count is not None else 'æ— é™åˆ¶'}")
        
        dialogues = self.dialogue_loader.get_dialogues_by_service(
            service=service,
            count=count,
            random_seed=self.random_seed
        )
        
        return dialogues
    
    def load_random_dialogues(self, count: int) -> List[Dict[str, Any]]:
        """
        éšæœºåŠ è½½æŒ‡å®šæ•°é‡çš„å¯¹è¯æ•°æ®
        
        Args:
            count: è¦åŠ è½½çš„å¯¹è¯æ•°é‡
            
        Returns:
            å¯¹è¯æ•°æ®åˆ—è¡¨
        """
        print(f"\nğŸ“‹ éšæœºåŠ è½½å¯¹è¯æ•°æ®")
        print(f"æ•°é‡: {count}")
        
        dialogues = self.dialogue_loader.get_random_dialogues(
            count=count,
            random_seed=self.random_seed
        )
        
        return dialogues
    
    def add_personality_labels(self, 
                             dialogues: List[Dict[str, Any]],
                             personality_type: str = "random",
                             personality_config: Optional[Dict[str, float]] = None) -> List[Dict[str, Any]]:
        """
        ä¸ºå¯¹è¯æ•°æ®æ·»åŠ æ€§æ ¼æ ‡ç­¾
        
        Args:
            dialogues: å¯¹è¯æ•°æ®åˆ—è¡¨
            personality_type: æ€§æ ¼ç±»å‹ ("random" æˆ– "specified")
            personality_config: æŒ‡å®šæ€§æ ¼é…ç½®ï¼ˆå½“personality_typeä¸º"specified"æ—¶ä½¿ç”¨ï¼‰
            
        Returns:
            æ·»åŠ äº†æ€§æ ¼æ ‡ç­¾çš„å¯¹è¯æ•°æ®åˆ—è¡¨
        """
        print(f"\nğŸ¯ æ·»åŠ æ€§æ ¼æ ‡ç­¾")
        print(f"æ€§æ ¼ç±»å‹: {personality_type}")
        print(f"å¯¹è¯æ•°é‡: {len(dialogues)}")
        
        if personality_type == "random":
            # æ‰¹é‡æ·»åŠ éšæœºæ€§æ ¼
            processed_dialogues = self.personality_adder.batch_add_random_personality(dialogues)
        
        elif personality_type == "specified":
            if personality_config is None:
                print("âš ï¸  æŒ‡å®šæ€§æ ¼æ¨¡å¼ä½†æœªæä¾›æ€§æ ¼é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ€§æ ¼é…ç½®ï¼ˆé«˜å¤–å‘æ€§ã€é«˜å®œäººæ€§ï¼‰
                personality_config = self.personality_adder.create_personality_template()
                # è®¾ç½®å¤–å‘æ€§å’Œå®œäººæ€§ä¸ºé«˜åˆ†
                for facet in self.personality_adder.NEO_PIR_FACETS['E']['facets']:
                    personality_config[facet] = 0.8
                for facet in self.personality_adder.NEO_PIR_FACETS['A']['facets']:
                    personality_config[facet] = 0.75
            
            processed_dialogues = self.personality_adder.batch_add_specified_personality(
                dialogues, personality_config
            )
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ€§æ ¼ç±»å‹: {personality_type}")
        
        return processed_dialogues
    
    def export_to_json(self, 
                      dialogues: List[Dict[str, Any]], 
                      filename: Optional[str] = None,
                      include_metadata: bool = True) -> str:
        """
        å°†å¤„ç†åçš„å¯¹è¯æ•°æ®å¯¼å‡ºä¸ºJSONæ–‡ä»¶
        
        Args:
            dialogues: å¤„ç†åçš„å¯¹è¯æ•°æ®
            filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®
            
        Returns:
            å¯¼å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"transformed_dialogues_{timestamp}.json"
        
        # ç¡®ä¿æ–‡ä»¶åä»¥.jsonç»“å°¾
        if not filename.endswith('.json'):
            filename += '.json'
        
        output_path = os.path.join(self.output_dir, filename)
        
        print(f"\nğŸ’¾ å¯¼å‡ºæ•°æ®åˆ°JSONæ–‡ä»¶")
        print(f"æ–‡ä»¶è·¯å¾„: {output_path}")
        print(f"å¯¹è¯æ•°é‡: {len(dialogues)}")
        
        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        export_data = {
            "dialogues": dialogues
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        if include_metadata:
            export_data["metadata"] = {
                "total_dialogues": len(dialogues),
                "export_timestamp": datetime.now().isoformat(),
                "random_seed": self.random_seed,
                "data_source": self.data_dir,
                "pipeline_version": "1.0.0"
            }
            
            # æ·»åŠ æ€§æ ¼ç»Ÿè®¡
            personality_stats = self._analyze_personality_distribution(dialogues)
            export_data["metadata"]["personality_statistics"] = personality_stats
        
        # å†™å…¥æ–‡ä»¶
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            print(f"âœ… å¯¼å‡ºæˆåŠŸ!")
            print(f"æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
            raise
    
    def _analyze_personality_distribution(self, dialogues: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æå¯¹è¯æ•°æ®ä¸­çš„æ€§æ ¼åˆ†å¸ƒç»Ÿè®¡
        
        Args:
            dialogues: åŒ…å«æ€§æ ¼æ ‡ç­¾çš„å¯¹è¯æ•°æ®
            
        Returns:
            æ€§æ ¼åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯
        """
        if not dialogues:
            return {}
        
        # ç»Ÿè®¡å¤§äº”äººæ ¼ç»´åº¦åˆ†æ•°
        dimension_stats = {
            'O': [], 'C': [], 'E': [], 'A': [], 'N': []
        }
        
        valid_dialogues = 0
        
        for dialogue in dialogues:
            personality = dialogue.get('personality', {})
            if isinstance(personality, dict) and 'big_five' in personality:
                valid_dialogues += 1
                for dimension, score in personality['big_five'].items():
                    if dimension in dimension_stats:
                        dimension_stats[dimension].append(score)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'valid_dialogues': valid_dialogues,
            'dimension_statistics': {}
        }
        
        for dimension, scores in dimension_stats.items():
            if scores:
                dimension_name = self.personality_adder.NEO_PIR_FACETS[dimension]['chinese_name']
                stats['dimension_statistics'][dimension] = {
                    'name': self.personality_adder.NEO_PIR_FACETS[dimension]['name'],
                    'chinese_name': dimension_name,
                    'mean': round(sum(scores) / len(scores), 3),
                    'min': round(min(scores), 3),
                    'max': round(max(scores), 3),
                    'count': len(scores)
                }
        
        return stats
    
    def process_dialogues(self,
                         load_method: str,
                         load_params: Dict[str, Any],
                         personality_type: str = "random",
                         personality_config: Optional[Dict[str, float]] = None,
                         output_filename: Optional[str] = None) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„å¯¹è¯å¤„ç†æµç¨‹
        
        Args:
            load_method: æ•°æ®åŠ è½½æ–¹æ³• ("by_id", "by_service", "random")
            load_params: åŠ è½½å‚æ•°
            personality_type: æ€§æ ¼ç±»å‹ ("random" æˆ– "specified")
            personality_config: æŒ‡å®šæ€§æ ¼é…ç½®
            output_filename: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        print("ğŸš€ å¼€å§‹æ‰§è¡Œå¯¹è¯å¤„ç†æµç¨‹")
        print("=" * 60)
        
        # 1. åŠ è½½å¯¹è¯æ•°æ®
        print(f"æ­¥éª¤ 1/3: åŠ è½½å¯¹è¯æ•°æ®")
        print(f"åŠ è½½æ–¹æ³•: {load_method}")
        
        if load_method == "by_id":
            dialogue_ids = load_params.get("dialogue_ids", [])
            dialogues = self.load_dialogues_by_id(dialogue_ids)
            
        elif load_method == "by_service":
            service = load_params.get("service")
            count = load_params.get("count")
            if not service:
                raise ValueError("ä½¿ç”¨by_serviceæ–¹æ³•æ—¶å¿…é¡»æä¾›serviceå‚æ•°")
            dialogues = self.load_dialogues_by_service(service, count)
            
        elif load_method == "random":
            count = load_params.get("count", 10)
            dialogues = self.load_random_dialogues(count)
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åŠ è½½æ–¹æ³•: {load_method}")
        
        if not dialogues:
            raise ValueError("æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•å¯¹è¯æ•°æ®")
        
        # 2. æ·»åŠ æ€§æ ¼æ ‡ç­¾
        print(f"\næ­¥éª¤ 2/3: æ·»åŠ æ€§æ ¼æ ‡ç­¾")
        processed_dialogues = self.add_personality_labels(
            dialogues, personality_type, personality_config
        )
        
        # 3. å¯¼å‡ºæ•°æ®
        print(f"\næ­¥éª¤ 3/3: å¯¼å‡ºæ•°æ®")
        output_path = self.export_to_json(processed_dialogues, output_filename)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ å¤„ç†æµç¨‹å®Œæˆ!")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        return output_path
    
    def get_available_services(self) -> List[str]:
        """
        è·å–å¯ç”¨çš„æœåŠ¡ç±»å‹åˆ—è¡¨
        
        Returns:
            æœåŠ¡ç±»å‹åˆ—è¡¨
        """
        return self.dialogue_loader.get_all_services()
    
    def print_data_summary(self):
        """æ‰“å°æ•°æ®é›†æ¦‚è§ˆä¿¡æ¯"""
        self.dialogue_loader.print_summary()


def create_example_pipeline():
    """åˆ›å»ºç¤ºä¾‹æµæ°´çº¿å¹¶æ¼”ç¤ºåŸºæœ¬åŠŸèƒ½"""
    print("ğŸ“‹ TransformationPipeline ç¤ºä¾‹æ¼”ç¤º")
    print("=" * 80)
    
    # åˆ›å»ºæµæ°´çº¿å®ä¾‹
    pipeline = TransformationPipeline(
        data_dir="datasets/sgd_processed_train",
        output_dir="output/pipeline_demo",
        random_seed=42
    )
    
    # æ‰“å°æ•°æ®æ¦‚è§ˆ
    print("\nğŸ“Š æ•°æ®é›†æ¦‚è§ˆ:")
    pipeline.print_data_summary()
    
    # è·å–å¯ç”¨æœåŠ¡
    services = pipeline.get_available_services()
    print(f"\nğŸ”§ å¯ç”¨æœåŠ¡ç±»å‹ (å…±{len(services)}ç§):")
    for i, service in enumerate(services[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
        print(f"  {i}. {service}")
    if len(services) > 10:
        print(f"  ... è¿˜æœ‰ {len(services) - 10} ä¸ªæœåŠ¡ç±»å‹")
    
    return pipeline


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="å¯¹è¯è½¬æ¢æµæ°´çº¿")
    
    # åŸºç¡€å‚æ•°
    parser.add_argument("--data-dir", default="datasets/sgd_processed_train",
                       help="SGDæ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--output-dir", default="output",
                       help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--random-seed", type=int, default=42,
                       help="éšæœºç§å­")
    
    # æ•°æ®åŠ è½½å‚æ•°
    parser.add_argument("--load-method", choices=["by_id", "by_service", "random"],
                       default="random", help="æ•°æ®åŠ è½½æ–¹æ³•")
    parser.add_argument("--dialogue-ids", nargs="+",
                       help="å¯¹è¯IDåˆ—è¡¨ (å½“load-methodä¸ºby_idæ—¶ä½¿ç”¨)")
    parser.add_argument("--service", help="æœåŠ¡ç±»å‹ (å½“load-methodä¸ºby_serviceæ—¶ä½¿ç”¨)")
    parser.add_argument("--count", type=int, default=10,
                       help="åŠ è½½æ•°é‡")
    
    # æ€§æ ¼å¤„ç†å‚æ•°
    parser.add_argument("--personality-type", choices=["random", "specified"],
                       default="random", help="æ€§æ ¼ç±»å‹")
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument("--output-filename", help="è¾“å‡ºæ–‡ä»¶å")
    parser.add_argument("--demo", action="store_true", help="è¿è¡Œç¤ºä¾‹æ¼”ç¤º")
    
    args = parser.parse_args()
    
    if args.demo:
        # è¿è¡Œæ¼”ç¤º
        pipeline = create_example_pipeline()
        
        # æ¼”ç¤ºä¸åŒçš„å¤„ç†æ–¹å¼
        demo_configs = [
            {
                "name": "éšæœº10ä¸ªå¯¹è¯",
                "load_method": "random",
                "load_params": {"count": 10},
                "output_filename": "demo_random_10.json"
            }
        ]
        
        if pipeline.get_available_services():
            demo_configs.append({
                "name": f"æœåŠ¡ç±»å‹: {pipeline.get_available_services()[0]}",
                "load_method": "by_service", 
                "load_params": {"service": pipeline.get_available_services()[0], "count": 5},
                "output_filename": "demo_service_5.json"
            })
        
        for config in demo_configs:
            print(f"\nğŸ¯ æ¼”ç¤º: {config['name']}")
            print("-" * 40)
            
            try:
                output_path = pipeline.process_dialogues(
                    load_method=config["load_method"],
                    load_params=config["load_params"],
                    output_filename=config["output_filename"]
                )
                print(f"âœ… æˆåŠŸ: {output_path}")
            except Exception as e:
                print(f"âŒ å¤±è´¥: {str(e)}")
    
    else:
        # æ‰§è¡ŒæŒ‡å®šçš„å¤„ç†ä»»åŠ¡
        pipeline = TransformationPipeline(
            data_dir=args.data_dir,
            output_dir=args.output_dir, 
            random_seed=args.random_seed
        )
        
        # å‡†å¤‡åŠ è½½å‚æ•°
        load_params = {"count": args.count}
        
        if args.load_method == "by_id":
            if not args.dialogue_ids:
                parser.error("ä½¿ç”¨by_idæ–¹æ³•æ—¶å¿…é¡»æä¾›--dialogue-idså‚æ•°")
            load_params["dialogue_ids"] = args.dialogue_ids
            
        elif args.load_method == "by_service":
            if not args.service:
                parser.error("ä½¿ç”¨by_serviceæ–¹æ³•æ—¶å¿…é¡»æä¾›--serviceå‚æ•°")
            load_params["service"] = args.service
        
        # æ‰§è¡Œå¤„ç†
        try:
            output_path = pipeline.process_dialogues(
                load_method=args.load_method,
                load_params=load_params,
                personality_type=args.personality_type,
                output_filename=args.output_filename
            )
            print(f"\nâœ… å¤„ç†å®Œæˆ: {output_path}")
            
        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {str(e)}")
            sys.exit(1)


if __name__ == "__main__":
    main()
