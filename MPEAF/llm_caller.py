"""
LLM Caller for Personality-driven Dialogue Transformation

This module implements an LLM caller that takes prompts from PromptGenerator
and calls LLM APIs to transform dialogues according to personality profiles.
"""

import logging
import requests
import json
import time
from typing import Dict, Any, Optional

try:
    from config.config import API_KEY_GPT_4, API_URL_GPT_40
except ImportError:
    from config.config import API_KEY_GPT_4, API_URL_GPT_40


class LLMCaller:
    """
    LLM caller for processing personality-driven dialogue transformation prompts
    
    This class takes prompts generated by PromptGenerator and calls LLM APIs
    to transform dialogues according to specified personality profiles.
    """
    
    def __init__(self, 
                 api_url: Optional[str] = None,
                 api_key: Optional[str] = None,
                 model_name: str = "gpt-4",
                 default_temperature: float = 0.7,
                 default_max_tokens: int = 4000,
                 timeout: int = 60,
                 max_retries: int = 3):
        """
        Initialize the LLM caller
        
        Args:
            api_url: LLM API endpoint URL (defaults to config value)
            api_key: API key for authentication (defaults to config value)
            model_name: Name of the model to use
            default_temperature: Default temperature for generation
            default_max_tokens: Default maximum tokens for generation
            timeout: Request timeout in seconds
            max_retries: Maximum number of retry attempts
        """
        self.api_url = api_url or API_URL_GPT_40
        self.api_key = api_key or API_KEY_GPT_4
        self.model_name = model_name
        self.default_temperature = default_temperature
        self.default_max_tokens = default_max_tokens
        self.timeout = timeout
        self.max_retries = max_retries
        
        self.logger = logging.getLogger(__name__)
        
        # Setup request headers
        self.headers = {
            "Content-Type": "application/json",
            "api-key": self.api_key
        }
        
        self.logger.info(f"LLMCaller initialized with model: {model_name}")

    def transform_dialogue(self, 
                         prompt: str,
                         temperature: Optional[float] = None,
                         max_tokens: Optional[int] = None,
                         top_p: float = 0.95) -> Dict[str, Any]:
        """
        Transform dialogue using LLM with the given prompt
        
        Args:
            prompt: Transformation prompt from PromptGenerator
            temperature: Generation temperature (uses default if None)
            max_tokens: Maximum tokens to generate (uses default if None)
            top_p: Top-p sampling parameter
            
        Returns:
            Dictionary containing the LLM response and metadata
            
        Raises:
            Exception: If API call fails after all retries
        """
        # Use default values if not specified
        temperature = temperature if temperature is not None else self.default_temperature
        max_tokens = max_tokens if max_tokens is not None else self.default_max_tokens
        
        # Prepare messages for the API call
        messages = [
            {
                "role": "system",
                "content": "You are an expert dialogue transformation assistant specializing in personality-driven text adaptation. Follow the provided instructions carefully and return the response in the exact JSON format requested."
            },
            {
                "role": "user", 
                "content": prompt
            }
        ]
        
        # Prepare payload
        payload = {
            "messages": messages,
            "temperature": temperature,
            "top_p": top_p,
            "max_tokens": max_tokens
        }
        
        # Make the API call with retries
        for attempt in range(self.max_retries):
            try:
                self.logger.info(f"Making LLM API call (attempt {attempt + 1}/{self.max_retries})")
                
                response = requests.post(
                    self.api_url,
                    headers=self.headers,
                    json=payload,
                    timeout=self.timeout
                )
                
                # Check if request was successful
                response.raise_for_status()
                
                # Parse response
                response_data = response.json()
                
                # Extract the generated content
                if 'choices' in response_data and len(response_data['choices']) > 0:
                    generated_content = response_data['choices'][0]['message']['content']
                    
                    result = {
                        'success': True,
                        'content': generated_content,
                        'usage': response_data.get('usage', {}),
                        'model': response_data.get('model', self.model_name),
                        'temperature': temperature,
                        'max_tokens': max_tokens,
                        'attempt': attempt + 1
                    }
                    
                    self.logger.info(f"LLM API call successful on attempt {attempt + 1}")
                    return result
                else:
                    raise ValueError("Invalid response format: missing choices")
                    
            except requests.exceptions.Timeout:
                self.logger.warning(f"Request timeout on attempt {attempt + 1}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                    continue
                else:
                    raise Exception("Request timed out after all retries")
                    
            except requests.exceptions.RequestException as e:
                self.logger.warning(f"Request error on attempt {attempt + 1}: {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                    continue
                else:
                    raise Exception(f"Request failed after all retries: {str(e)}")
                    
            except json.JSONDecodeError:
                self.logger.warning(f"JSON decode error on attempt {attempt + 1}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)
                    continue
                else:
                    raise Exception("Failed to decode JSON response after all retries")
                    
            except Exception as e:
                self.logger.error(f"Unexpected error on attempt {attempt + 1}: {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)
                    continue
                else:
                    raise Exception(f"Unexpected error after all retries: {str(e)}")
        
        # This should never be reached due to the raise statements above
        raise Exception("Failed to complete API call")

    def get_api_status(self) -> Dict[str, Any]:
        """
        Check API status and connectivity
        
        Returns:
            Dictionary containing API status information
        """
        try:
            # Simple test call to check API availability
            test_payload = {
                "messages": [{"role": "user", "content": "Hello"}],
                "temperature": 0.1,
                "max_tokens": 10
            }
            
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=test_payload,
                timeout=10
            )
            
            if response.status_code == 200:
                return {
                    'status': 'healthy',
                    'api_url': self.api_url,
                    'model': self.model_name,
                    'response_time_ms': response.elapsed.total_seconds() * 1000
                }
            else:
                return {
                    'status': 'error',
                    'status_code': response.status_code,
                    'error': response.text
                }
                
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e)
            }

    def set_api_credentials(self, api_url: str, api_key: str):
        """
        Update API credentials
        
        Args:
            api_url: New API URL
            api_key: New API key
        """
        self.api_url = api_url
        self.api_key = api_key
        self.headers["api-key"] = api_key
        self.logger.info("API credentials updated")
